{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "\n",
    "# GPU 선택 -> '1': 두 번째\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# GPU 메모리의 동적 할당 허용\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\n",
    "    '가렵다',\n",
    "    '기절',\n",
    "    '부러지다',\n",
    "    '어제',\n",
    "    '어지러움',\n",
    "    '열나다',\n",
    "    '오늘',\n",
    "    '진통제',\n",
    "    '창백하다',\n",
    "    '토하다'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('C:/Users/mshof/Desktop/seq_data/seq_slice_1715018422.npy'),\n",
    "    np.load('C:/Users/mshof/Desktop/seq_data/seq_flip_slice_1715018362.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape\n",
    "# (데이터의 개수, 프레임 사이즈, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스의 마지막 열 제외한 모든 열 가져와 할당\n",
    "# 첫 번째 행의 마지막 열은 라벨 값\n",
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(np.unique(labels))    # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)  # 입력 데이터\n",
    "y_data = y_data.astype(np.float32)  # 레이블\n",
    "\n",
    "# train data : validation data : test data = 6 : 2 : 2\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=2024)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.25, random_state=2024)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128,  activation='relu', input_shape=x_train.shape[1:3]),   # input -> (None, 60, 252)\n",
    "    Dropout(0.2),   # 20%의 드롭아웃 비율\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile(최적화 알고리즘, 레이블 클래스 2개 이상일 때 사용하는 손실 함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, n 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"테스트 손실: {test_loss:.3f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\")\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# 다중 레이블 혼동 행렬로 모델 평가\n",
    "# [[True Negative, False Positive],\n",
    "# [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
