{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "\n",
    "# GPU 선택 -> '1': 두 번째\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# GPU 메모리의 동적 할당 허용\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setting import actions\n",
    "\n",
    "train_data = np.load('C:/Users/mshof/Desktop/train_seq_data/seq_1717834187.npy')\n",
    "val_data = np.load('C:/Users/mshof/Desktop/val_seq_data/seq_1717834312.npy')\n",
    "test_data = np.load('C:/Users/mshof/Desktop/test_seq_data/seq_1717834379.npy')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)\n",
    "# (데이터의 개수, 프레임 사이즈, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스의 마지막 요소 제외한 모든 값 가져와 할당\n",
    "# 마지막 요소는 라벨 값\n",
    "\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "\n",
    "t_data = train_data[:, :, :-1]\n",
    "t_labels = train_data[:, 0, -1]\n",
    "\n",
    "v_data = val_data[:, :, :-1]\n",
    "v_labels = val_data[:, 0, -1]\n",
    "\n",
    "te_data = test_data[:, :, :-1]\n",
    "te_labels = test_data[:, 0, -1]\n",
    "\n",
    "print(t_data.shape, v_data.shape, te_data.shape)\n",
    "print(t_labels.shape, v_labels.shape, te_labels.shape)\n",
    "print(np.unique(t_labels))  # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(train_labels, num_classes=len(actions))\n",
    "y_data.shape\n",
    "# y_data 형태 -> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.astype(np.float64)  # 입력 데이터\n",
    "y_data = y_data.astype(np.float64)  # 레이블\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128,  activation='relu', input_shape=x_train.shape[1:3]),   # input -> (None, 30, 252)\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile(최적화 알고리즘, 레이블 클래스 2개 이상일 때 사용하는 손실 함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=50,\n",
    "    shuffle=False,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, n 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, verbose=1, mode='auto'),\n",
    "        # early stopping 적용\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"테스트 손실: {test_loss:.3f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\")\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# 다중 레이블 혼동 행렬로 모델 평가\n",
    "# [[True Negative, False Positive],\n",
    "# [False Negative, True Positive]]\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
