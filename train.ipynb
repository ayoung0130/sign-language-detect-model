{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "base_dir = os.getenv('BASE_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9162, 15, 235)\n"
     ]
    }
   ],
   "source": [
    "data = np.concatenate([\n",
    "    np.load(os.path.join(base_dir, f'seq_data/seq_npy_1725890673_15_15.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/seq_npy_flip_1725890673_15_15.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/seq_npy_shift_1725890673_15_15.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/seq_npy_flip_shift_1725890674_15_15.npy')),\n",
    "], axis=0)\n",
    "\n",
    "print(data.shape)\n",
    "# (데이터의 개수, 프레임 사이즈, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "(9162, 15, 234)\n",
      "(9162,)\n",
      "(9162, 20)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n"
     ]
    }
   ],
   "source": [
    "from setting import actions\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 데이터 분리 및 전처리\n",
    "x_data = data[:, :, :-1]    # 시퀀스의 마지막 요소 제외한 모든 값 가져와 할당\n",
    "labels = data[:, 0, -1]     # 마지막 요소는 레이블 값\n",
    "\n",
    "# 원-핫 인코딩으로 변환\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(y_data.shape)         # y_data 형태 -> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...]\n",
    "print(np.unique(labels))    # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2, stratify=labels)\n",
    "\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               502784    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545236 (2.08 MB)\n",
      "Trainable params: 545236 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(256, activation='tanh', input_shape=x_data.shape[1:3]),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax'),\n",
    "])\n",
    "\n",
    "# 모델 컴파일 (최적화 알고리즘, 레이블 클래스 2개 이상일 때 사용하는 손실 함수, 모델평가지표)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7762 - accuracy: 0.4395\n",
      "Epoch 1: loss improved from inf to 1.77618, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 46ms/step - loss: 1.7762 - accuracy: 0.4395 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.8871 - accuracy: 0.6983\n",
      "Epoch 2: loss improved from 1.77618 to 0.88694, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.8869 - accuracy: 0.6981 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5731 - accuracy: 0.8094\n",
      "Epoch 3: loss improved from 0.88694 to 0.57061, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.5706 - accuracy: 0.8104 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4575 - accuracy: 0.8391\n",
      "Epoch 4: loss improved from 0.57061 to 0.45764, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4576 - accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8941\n",
      "Epoch 5: loss improved from 0.45764 to 0.31342, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.3134 - accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8972\n",
      "Epoch 6: loss improved from 0.31342 to 0.29258, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2926 - accuracy: 0.8978 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.9186\n",
      "Epoch 7: loss improved from 0.29258 to 0.24196, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2420 - accuracy: 0.9186 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9270\n",
      "Epoch 8: loss improved from 0.24196 to 0.21419, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2142 - accuracy: 0.9270 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9485\n",
      "Epoch 9: loss improved from 0.21419 to 0.15735, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.1573 - accuracy: 0.9485 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9478\n",
      "Epoch 10: loss did not improve from 0.15735\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.1574 - accuracy: 0.9478 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9564\n",
      "Epoch 11: loss improved from 0.15735 to 0.13302, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.1330 - accuracy: 0.9568 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9569\n",
      "Epoch 12: loss improved from 0.13302 to 0.12143, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.1214 - accuracy: 0.9570 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9664\n",
      "Epoch 13: loss improved from 0.12143 to 0.09999, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.1000 - accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 0.9599\n",
      "Epoch 14: loss did not improve from 0.09999\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.1185 - accuracy: 0.9599 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9799\n",
      "Epoch 15: loss improved from 0.09999 to 0.06585, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.0659 - accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9723\n",
      "Epoch 16: loss did not improve from 0.06585\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.0887 - accuracy: 0.9724 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9722\n",
      "Epoch 17: loss did not improve from 0.06585\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.0879 - accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9926\n",
      "Epoch 18: loss improved from 0.06585 to 0.03063, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.0306 - accuracy: 0.9926 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9722\n",
      "Epoch 19: loss did not improve from 0.03063\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.0880 - accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9745\n",
      "Epoch 20: loss did not improve from 0.03063\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.0798 - accuracy: 0.9747 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9744\n",
      "Epoch 21: loss did not improve from 0.03063\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.0737 - accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9820\n",
      "Epoch 22: loss did not improve from 0.03063\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.0587 - accuracy: 0.9821 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9889\n",
      "Epoch 23: loss did not improve from 0.03063\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.0381 - accuracy: 0.9889 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9924\n",
      "Epoch 24: loss improved from 0.03063 to 0.02710, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.0271 - accuracy: 0.9925 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9834\n",
      "Epoch 25: loss did not improve from 0.02710\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.0470 - accuracy: 0.9835 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9755\n",
      "Epoch 26: loss did not improve from 0.02710\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0791 - accuracy: 0.9756 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9750\n",
      "Epoch 27: loss did not improve from 0.02710\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.0800 - accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9854\n",
      "Epoch 28: loss did not improve from 0.02710\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.0498 - accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9844\n",
      "Epoch 29: loss did not improve from 0.02710\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.0510 - accuracy: 0.9845 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9953\n",
      "Epoch 30: loss improved from 0.02710 to 0.01691, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.0169 - accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9879\n",
      "Epoch 31: loss did not improve from 0.01691\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.0415 - accuracy: 0.9880 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9955\n",
      "Epoch 32: loss improved from 0.01691 to 0.01499, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.0150 - accuracy: 0.9955 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9924\n",
      "Epoch 33: loss did not improve from 0.01499\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.0335 - accuracy: 0.9917 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0816 - accuracy: 0.9784\n",
      "Epoch 34: loss did not improve from 0.01499\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0810 - accuracy: 0.9786 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9892\n",
      "Epoch 35: loss did not improve from 0.01499\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0336 - accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9897\n",
      "Epoch 36: loss did not improve from 0.01499\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.0365 - accuracy: 0.9897 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9970\n",
      "Epoch 37: loss improved from 0.01499 to 0.01088, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.0109 - accuracy: 0.9971 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 38: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.0113 - accuracy: 0.9962 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9909\n",
      "Epoch 39: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0300 - accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9760\n",
      "Epoch 40: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.0729 - accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9745\n",
      "Epoch 41: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.0807 - accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9835\n",
      "Epoch 42: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.0604 - accuracy: 0.9836 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9856\n",
      "Epoch 43: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.0439 - accuracy: 0.9856 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9941\n",
      "Epoch 44: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.0179 - accuracy: 0.9941 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9878\n",
      "Epoch 45: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.0378 - accuracy: 0.9878 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9898\n",
      "Epoch 46: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.0332 - accuracy: 0.9897 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9956\n",
      "Epoch 47: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.0142 - accuracy: 0.9955 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9856\n",
      "Epoch 48: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0493 - accuracy: 0.9856 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9893\n",
      "Epoch 49: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.0345 - accuracy: 0.9894 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9923\n",
      "Epoch 50: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.0282 - accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9912\n",
      "Epoch 51: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.0330 - accuracy: 0.9912 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9952\n",
      "Epoch 52: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0172 - accuracy: 0.9952 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 53: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0163 - accuracy: 0.9951 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9922\n",
      "Epoch 54: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0272 - accuracy: 0.9923 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 55: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0176 - accuracy: 0.9941 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9901\n",
      "Epoch 56: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.0332 - accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9856\n",
      "Epoch 57: loss did not improve from 0.01088\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.0482 - accuracy: 0.9856 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9964\n",
      "Epoch 58: loss did not improve from 0.01088\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.0122 - accuracy: 0.9964 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 59: loss improved from 0.01088 to 0.00222, saving model to models\\model.keras\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.0022 - accuracy: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.6196e-04 - accuracy: 1.0000\n",
      "Epoch 60: loss improved from 0.00222 to 0.00096, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 9.5923e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.5547e-04 - accuracy: 1.0000\n",
      "Epoch 61: loss improved from 0.00096 to 0.00076, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 7.5547e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.2817e-04 - accuracy: 1.0000\n",
      "Epoch 62: loss improved from 0.00076 to 0.00063, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 6.2659e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.0666e-04 - accuracy: 1.0000\n",
      "Epoch 63: loss improved from 0.00063 to 0.00040, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 4.0410e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.0399e-04 - accuracy: 1.0000\n",
      "Epoch 64: loss improved from 0.00040 to 0.00040, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 4.0286e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8290e-04 - accuracy: 1.0000\n",
      "Epoch 65: loss improved from 0.00040 to 0.00038, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 3.8290e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.8926e-04 - accuracy: 1.0000\n",
      "Epoch 66: loss improved from 0.00038 to 0.00029, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 2.9356e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 3.0072e-04 - accuracy: 1.0000\n",
      "Epoch 67: loss did not improve from 0.00029\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 2.9918e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.5911e-04 - accuracy: 1.0000\n",
      "Epoch 68: loss improved from 0.00029 to 0.00026, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.5985e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.0840e-04 - accuracy: 1.0000\n",
      "Epoch 69: loss improved from 0.00026 to 0.00021, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 2.0797e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7219e-04 - accuracy: 1.0000\n",
      "Epoch 70: loss improved from 0.00021 to 0.00017, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 1.7357e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.7784e-04 - accuracy: 1.0000\n",
      "Epoch 71: loss did not improve from 0.00017\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 1.7784e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7026e-04 - accuracy: 1.0000\n",
      "Epoch 72: loss improved from 0.00017 to 0.00017, saving model to models\\model.keras\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 1.6998e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6715e-04 - accuracy: 1.0000\n",
      "Epoch 73: loss improved from 0.00017 to 0.00017, saving model to models\\model.keras\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 1.6715e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2874e-04 - accuracy: 1.0000\n",
      "Epoch 74: loss improved from 0.00017 to 0.00013, saving model to models\\model.keras\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 1.2825e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7175e-04 - accuracy: 1.0000\n",
      "Epoch 75: loss did not improve from 0.00013\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 1.7517e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3649e-04 - accuracy: 1.0000\n",
      "Epoch 76: loss did not improve from 0.00013\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 1.3649e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.9582e-04 - accuracy: 1.0000\n",
      "Epoch 77: loss did not improve from 0.00013\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 1.9485e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.9706e-05 - accuracy: 1.0000\n",
      "Epoch 78: loss improved from 0.00013 to 0.00010, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 9.9289e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0189e-04 - accuracy: 1.0000\n",
      "Epoch 79: loss did not improve from 0.00010\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 1.0152e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.6011e-05 - accuracy: 1.0000\n",
      "Epoch 80: loss improved from 0.00010 to 0.00010, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 9.5835e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0747e-04 - accuracy: 1.0000\n",
      "Epoch 81: loss did not improve from 0.00010\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.0687e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.2720e-05 - accuracy: 1.0000\n",
      "Epoch 82: loss improved from 0.00010 to 0.00007, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 7.2549e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.5426e-05 - accuracy: 1.0000\n",
      "Epoch 83: loss did not improve from 0.00007\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 9.4901e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3057e-04 - accuracy: 1.0000\n",
      "Epoch 84: loss did not improve from 0.00007\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 1.3057e-04 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.7050e-05 - accuracy: 1.0000\n",
      "Epoch 85: loss did not improve from 0.00007\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 7.7050e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.6716e-05 - accuracy: 1.0000\n",
      "Epoch 86: loss improved from 0.00007 to 0.00007, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 6.7739e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 8.3181e-05 - accuracy: 1.0000\n",
      "Epoch 87: loss did not improve from 0.00007\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 8.3181e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 7.2774e-05 - accuracy: 1.0000\n",
      "Epoch 88: loss did not improve from 0.00007\n",
      "72/72 [==============================] - 7s 98ms/step - loss: 7.2774e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.3461e-05 - accuracy: 1.0000\n",
      "Epoch 89: loss improved from 0.00007 to 0.00006, saving model to models\\model.keras\n",
      "72/72 [==============================] - 7s 95ms/step - loss: 6.3461e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.7586e-05 - accuracy: 1.0000\n",
      "Epoch 90: loss did not improve from 0.00006\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 6.7586e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.9714e-05 - accuracy: 1.0000\n",
      "Epoch 91: loss improved from 0.00006 to 0.00005, saving model to models\\model.keras\n",
      "72/72 [==============================] - 7s 103ms/step - loss: 4.9714e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.0906e-05 - accuracy: 1.0000\n",
      "Epoch 92: loss did not improve from 0.00005\n",
      "72/72 [==============================] - 8s 114ms/step - loss: 5.0906e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 6.1704e-05 - accuracy: 1.0000\n",
      "Epoch 93: loss did not improve from 0.00005\n",
      "72/72 [==============================] - 8s 114ms/step - loss: 6.1704e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.9730e-05 - accuracy: 1.0000\n",
      "Epoch 94: loss improved from 0.00005 to 0.00004, saving model to models\\model.keras\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 3.9730e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.5238e-05 - accuracy: 1.0000\n",
      "Epoch 95: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 7s 103ms/step - loss: 4.5238e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.0067e-05 - accuracy: 1.0000\n",
      "Epoch 96: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 5.0067e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 5.2168e-05 - accuracy: 1.0000\n",
      "Epoch 97: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 5.2168e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.1140e-05 - accuracy: 1.0000\n",
      "Epoch 98: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 7s 104ms/step - loss: 4.1140e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8468e-05 - accuracy: 1.0000\n",
      "Epoch 99: loss improved from 0.00004 to 0.00004, saving model to models\\model.keras\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 3.8468e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.9627e-05 - accuracy: 1.0000\n",
      "Epoch 100: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 7s 98ms/step - loss: 3.9627e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 4.1137e-05 - accuracy: 1.0000\n",
      "Epoch 101: loss did not improve from 0.00004\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 4.1137e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 3.2415e-05 - accuracy: 1.0000\n",
      "Epoch 102: loss improved from 0.00004 to 0.00003, saving model to models\\model.keras\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "72/72 [==============================] - 7s 94ms/step - loss: 3.2280e-05 - accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.7437e-05 - accuracy: 1.0000\n",
      "Epoch 103: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 3.7437e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 104/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.9405e-05 - accuracy: 1.0000\n",
      "Epoch 104: loss improved from 0.00003 to 0.00003, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 2.9356e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.9794e-05 - accuracy: 1.0000\n",
      "Epoch 105: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 3.0562e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.8311e-05 - accuracy: 1.0000\n",
      "Epoch 106: loss improved from 0.00003 to 0.00003, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 2.8311e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.4636e-05 - accuracy: 1.0000\n",
      "Epoch 107: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 3.4636e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.8342e-05 - accuracy: 1.0000\n",
      "Epoch 108: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.8342e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.8603e-05 - accuracy: 1.0000\n",
      "Epoch 109: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 2.8603e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 3.6700e-05 - accuracy: 1.0000\n",
      "Epoch 110: loss did not improve from 0.00003\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 3.6597e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.4175e-05 - accuracy: 1.0000\n",
      "Epoch 111: loss improved from 0.00003 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 2.4287e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.9717e-05 - accuracy: 1.0000\n",
      "Epoch 112: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 3.0859e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.7376e-05 - accuracy: 1.0000\n",
      "Epoch 113: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 2.7220e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.5075e-05 - accuracy: 1.0000\n",
      "Epoch 114: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 2.4978e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.4977e-05 - accuracy: 1.0000\n",
      "Epoch 115: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 2.4982e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.5599e-05 - accuracy: 1.0000\n",
      "Epoch 116: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 2.6475e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.3382e-05 - accuracy: 1.0000\n",
      "Epoch 117: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 2.3275e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.0195e-05 - accuracy: 1.0000\n",
      "Epoch 118: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 2.0195e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.9466e-05 - accuracy: 1.0000\n",
      "Epoch 119: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 1.9414e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.9997e-05 - accuracy: 1.0000\n",
      "Epoch 120: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 2.0199e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.6965e-05 - accuracy: 1.0000\n",
      "Epoch 121: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 2.6965e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.4596e-05 - accuracy: 1.0000\n",
      "Epoch 122: loss did not improve from 0.00002\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 2.4504e-05 - accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.1654e-05 - accuracy: 1.0000\n",
      "Epoch 123: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 2.1597e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 124/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.1943e-05 - accuracy: 1.0000\n",
      "Epoch 124: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 4.1681e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 125/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.6305e-05 - accuracy: 1.0000\n",
      "Epoch 125: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.6353e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 126/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8298e-05 - accuracy: 1.0000\n",
      "Epoch 126: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.8309e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 127/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.3823e-05 - accuracy: 1.0000\n",
      "Epoch 127: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 2.3688e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 128/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8247e-05 - accuracy: 1.0000\n",
      "Epoch 128: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.8144e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 129/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8746e-05 - accuracy: 1.0000\n",
      "Epoch 129: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.8800e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 130/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8910e-05 - accuracy: 1.0000\n",
      "Epoch 130: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.8802e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 131/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8880e-05 - accuracy: 1.0000\n",
      "Epoch 131: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.9030e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 132/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.5611e-05 - accuracy: 1.0000\n",
      "Epoch 132: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.5669e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 133/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.5580e-05 - accuracy: 1.0000\n",
      "Epoch 133: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.5511e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 134/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.6814e-05 - accuracy: 1.0000\n",
      "Epoch 134: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 1.6726e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 135/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.8799e-05 - accuracy: 1.0000\n",
      "Epoch 135: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.8751e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 136/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7248e-05 - accuracy: 1.0000\n",
      "Epoch 136: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.7141e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 137/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7640e-05 - accuracy: 1.0000\n",
      "Epoch 137: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.7561e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 138/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.0499e-05 - accuracy: 1.0000\n",
      "Epoch 138: loss did not improve from 0.00002\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 2.0416e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 139/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.5137e-05 - accuracy: 1.0000\n",
      "Epoch 139: loss improved from 0.00002 to 0.00002, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.5089e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 140/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.3971e-05 - accuracy: 1.0000\n",
      "Epoch 140: loss improved from 0.00002 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 1.3884e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 141/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.5654e-05 - accuracy: 1.0000\n",
      "Epoch 141: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 1.5583e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 142/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.3795e-05 - accuracy: 1.0000\n",
      "Epoch 142: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 1.3713e-05 - accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 143/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.3555e-05 - accuracy: 1.0000\n",
      "Epoch 143: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 1.3583e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 144/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2795e-05 - accuracy: 1.0000\n",
      "Epoch 144: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.2773e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 145/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7780e-05 - accuracy: 1.0000\n",
      "Epoch 145: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 1.7699e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 146/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6000e-05 - accuracy: 1.0000\n",
      "Epoch 146: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.6000e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 147/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2057e-05 - accuracy: 1.0000\n",
      "Epoch 147: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.2028e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 148/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2493e-05 - accuracy: 1.0000\n",
      "Epoch 148: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.2451e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 149/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.4159e-05 - accuracy: 1.0000\n",
      "Epoch 149: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.4081e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 150/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7888e-05 - accuracy: 1.0000\n",
      "Epoch 150: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.7943e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 151/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2638e-05 - accuracy: 1.0000\n",
      "Epoch 151: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 1.2867e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 152/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2728e-05 - accuracy: 1.0000\n",
      "Epoch 152: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.2750e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 153/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2892e-05 - accuracy: 1.0000\n",
      "Epoch 153: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 1.2894e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 154/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1139e-05 - accuracy: 1.0000\n",
      "Epoch 154: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.1114e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 155/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3448e-05 - accuracy: 1.0000\n",
      "Epoch 155: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 1.3448e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 156/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2541e-05 - accuracy: 1.0000\n",
      "Epoch 156: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 1.2528e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 157/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.3823e-05 - accuracy: 1.0000\n",
      "Epoch 157: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.3744e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 158/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.8322e-06 - accuracy: 1.0000\n",
      "Epoch 158: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 9.8091e-06 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 159/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.5642e-06 - accuracy: 1.0000\n",
      "Epoch 159: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 9.5632e-06 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 160/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2128e-05 - accuracy: 1.0000\n",
      "Epoch 160: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.2057e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 161/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0101e-05 - accuracy: 1.0000\n",
      "Epoch 161: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.0077e-05 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 162/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.3325e-06 - accuracy: 1.0000\n",
      "Epoch 162: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 9.3059e-06 - accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 163/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0723e-05 - accuracy: 1.0000\n",
      "Epoch 163: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.0725e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 164/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.4599e-05 - accuracy: 1.0000\n",
      "Epoch 164: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.5153e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 165/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1663e-05 - accuracy: 1.0000\n",
      "Epoch 165: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.1590e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 166/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0018e-05 - accuracy: 1.0000\n",
      "Epoch 166: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 9.9965e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 167/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.3426e-06 - accuracy: 1.0000\n",
      "Epoch 167: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 9.3313e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 168/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0278e-05 - accuracy: 1.0000\n",
      "Epoch 168: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 1.0357e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 169/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1622e-05 - accuracy: 1.0000\n",
      "Epoch 169: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.1543e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 170/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7165e-06 - accuracy: 1.0000\n",
      "Epoch 170: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 8.6844e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 171/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0468e-05 - accuracy: 1.0000\n",
      "Epoch 171: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 1.0465e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 172/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.7703e-05 - accuracy: 1.0000\n",
      "Epoch 172: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 1.7633e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 173/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2115e-05 - accuracy: 1.0000\n",
      "Epoch 173: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 1.2050e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 174/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1557e-05 - accuracy: 1.0000\n",
      "Epoch 174: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 1.1695e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 175/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.7003e-06 - accuracy: 1.0000\n",
      "Epoch 175: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 7.6659e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 176/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.4029e-06 - accuracy: 1.0000\n",
      "Epoch 176: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 8.3663e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 177/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2611e-05 - accuracy: 1.0000\n",
      "Epoch 177: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.2564e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 178/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2602e-05 - accuracy: 1.0000\n",
      "Epoch 178: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 1.2634e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 179/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7010e-06 - accuracy: 1.0000\n",
      "Epoch 179: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 8.6750e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 180/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.9851e-06 - accuracy: 1.0000\n",
      "Epoch 180: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 9.9376e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 181/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0690e-05 - accuracy: 1.0000\n",
      "Epoch 181: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.0685e-05 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 182/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.6807e-06 - accuracy: 1.0000\n",
      "Epoch 182: loss did not improve from 0.00001\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 8.6462e-06 - accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 183/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.1880e-06 - accuracy: 1.0000\n",
      "Epoch 183: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 9.1676e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 184/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7401e-06 - accuracy: 1.0000\n",
      "Epoch 184: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 8.6875e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 185/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0204e-05 - accuracy: 1.0000\n",
      "Epoch 185: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.0169e-05 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 186/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0439e-05 - accuracy: 1.0000\n",
      "Epoch 186: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 1.0375e-05 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 187/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.7958e-06 - accuracy: 1.0000\n",
      "Epoch 187: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 7.7508e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 188/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7298e-06 - accuracy: 1.0000\n",
      "Epoch 188: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 8.7700e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 189/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.3023e-06 - accuracy: 1.0000\n",
      "Epoch 189: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 8.2490e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 190/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.4251e-06 - accuracy: 1.0000\n",
      "Epoch 190: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 8.3795e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 191/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7785e-06 - accuracy: 1.0000\n",
      "Epoch 191: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 8.7410e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 192/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.6968e-06 - accuracy: 1.0000\n",
      "Epoch 192: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 8.6526e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 193/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.4119e-06 - accuracy: 1.0000\n",
      "Epoch 193: loss improved from 0.00001 to 0.00001, saving model to models\\model.keras\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 6.3896e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 194/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.4863e-06 - accuracy: 1.0000\n",
      "Epoch 194: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 8.4614e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 195/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.0124e-05 - accuracy: 1.0000\n",
      "Epoch 195: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 1.0215e-05 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 196/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.7186e-06 - accuracy: 1.0000\n",
      "Epoch 196: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 7.7081e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 197/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7941e-06 - accuracy: 1.0000\n",
      "Epoch 197: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 8.7666e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 198/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.2280e-05 - accuracy: 1.0000\n",
      "Epoch 198: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.2197e-05 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 199/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.8813e-05 - accuracy: 1.0000\n",
      "Epoch 199: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 2.8593e-05 - accuracy: 1.0000 - lr: 1.5625e-05\n",
      "Epoch 200/200\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.4242e-06 - accuracy: 1.0000\n",
      "Epoch 200: loss did not improve from 0.00001\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 7.3799e-06 - accuracy: 1.0000 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    x_data,\n",
    "    y_data,\n",
    "    # validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    callbacks=[\n",
    "        # save_best_only -> 모델 정확도가 이전보다 향상된 경우에만 모델 저장\n",
    "        ModelCheckpoint('models/model.keras', monitor='loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "        # 정확도 개선이 없을시 학습률(factor) 0.5배로 감소, n 에포크 동안 개선 없을 경우 학습률 감소\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=20, verbose=1, mode='auto'),\n",
    "        # early stopping 적용\n",
    "        # EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 데이터/검증 데이터 정확도/손실 그래프\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "# loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "# acc_ax.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
