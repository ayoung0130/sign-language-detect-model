{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os   # 운영체제와 상호작용하기 위한 모듈\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "base_dir = os.getenv('BASE_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13656, 20, 235)\n",
      "(1932, 20, 235)\n"
     ]
    }
   ],
   "source": [
    "# 기존에 학습시킨 데이터\n",
    "data = np.concatenate([\n",
    "    np.load(os.path.join(base_dir, f'seq_data/20words/seq_npy_1727115433_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/20words/seq_npy_flip_1727115434_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/20words/seq_npy_shift_1727115434_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'seq_data/20words/seq_npy_flip_shift_1727115435_20_10.npy')),\n",
    "], axis=0)\n",
    "\n",
    "# 추가 학습시킬 데이터\n",
    "new_data = np.concatenate([\n",
    "    np.load(os.path.join(base_dir, f'ft_seq/seq_ft_1727487535_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'ft_seq/seq_ft_flip_1727487535_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'ft_seq/seq_ft_shift_1727487535_20_10.npy')),\n",
    "    np.load(os.path.join(base_dir, f'ft_seq/seq_ft_flip_shift_1727487535_20_10.npy')),\n",
    "], axis=0)\n",
    "\n",
    "print(data.shape)\n",
    "print(new_data.shape)\n",
    "# (프레임 수, 시퀀스 길이, 한 프레임당 데이터 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "(1932, 20, 234)\n",
      "(1932,)\n",
      "(1932, 20)\n",
      "[ 3. 10. 14.]\n"
     ]
    }
   ],
   "source": [
    "from setting import actions\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# 기존 데이터\n",
    "# 데이터 분리 및 전처리\n",
    "x_data = data[:, :, :-1]    # 시퀀스의 마지막 요소 제외한 모든 값 가져와 할당\n",
    "labels = data[:, 0, -1]     # 마지막 요소는 레이블 값\n",
    "y_data = to_categorical(labels, num_classes=len(actions))   # 원-핫 인코딩으로 변환\n",
    "\n",
    "# 추가 학습 시킬 데이터\n",
    "# 데이터 분리 및 전처리\n",
    "new_x = new_data[:, :, :-1]    # 시퀀스의 마지막 요소 제외한 모든 값 가져와 할당\n",
    "new_labels = new_data[:, 0, -1]     # 마지막 요소는 레이블 값\n",
    "new_y = to_categorical(new_labels, num_classes=len(actions))    # 원-핫 인코딩으로 변환\n",
    "\n",
    "print(new_x.shape)\n",
    "print(new_labels.shape)\n",
    "print(new_y.shape)         # y_data 형태 -> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...]\n",
    "print(np.unique(new_labels))    # 레이블 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9896\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95496, saving model to models\\model.keras\n",
      "61/61 [==============================] - 11s 149ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 0.2467 - val_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9859\n",
      "Epoch 2: val_accuracy improved from 0.95496 to 0.96331, saving model to models\\model.keras\n",
      "61/61 [==============================] - 8s 129ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.1517 - val_accuracy: 0.9633 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9928\n",
      "Epoch 3: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 121ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.2377 - val_accuracy: 0.9513 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 4: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 122ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9959\n",
      "Epoch 5: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 155ms/step - loss: 0.0199 - accuracy: 0.9959 - val_loss: 0.3273 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9964\n",
      "Epoch 6: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 127ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.3761 - val_accuracy: 0.9288 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 8.2568e-04 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 117ms/step - loss: 8.2568e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9332 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.7497e-04 - accuracy: 1.0000\n",
      "Epoch 8: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 153ms/step - loss: 4.7497e-04 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 3.2225e-04 - accuracy: 1.0000\n",
      "Epoch 9: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 130ms/step - loss: 3.2225e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9341 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 3.9139e-04 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 132ms/step - loss: 3.8971e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.5136e-04 - accuracy: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 115ms/step - loss: 2.5156e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 2.2407e-04 - accuracy: 1.0000\n",
      "Epoch 12: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "61/61 [==============================] - 7s 123ms/step - loss: 2.2107e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9320 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7127e-04 - accuracy: 1.0000\n",
      "Epoch 13: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 125ms/step - loss: 1.7127e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9320 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 2.0466e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 127ms/step - loss: 2.0466e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9316 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 1.4476e-04 - accuracy: 1.0000\n",
      "Epoch 15: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 114ms/step - loss: 1.4233e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9313 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.6586e-04 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 138ms/step - loss: 1.6729e-04 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9306 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.3240e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 143ms/step - loss: 1.5872e-04 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.1809e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 119ms/step - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9290 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.5929e-04 - accuracy: 0.9995\n",
      "Epoch 19: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 109ms/step - loss: 6.5929e-04 - accuracy: 0.9995 - val_loss: 0.3703 - val_accuracy: 0.9306 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 2.7873e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 6s 106ms/step - loss: 2.7728e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9314 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 9.9023e-05 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 114ms/step - loss: 9.9520e-05 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9314 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.4006e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "61/61 [==============================] - 8s 133ms/step - loss: 1.3938e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9312 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.2696e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 125ms/step - loss: 1.2643e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9313 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 9.7489e-05 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 145ms/step - loss: 9.7977e-05 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9310 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 2.4422e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 141ms/step - loss: 2.4358e-04 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.1603e-04 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 156ms/step - loss: 1.1603e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4290e-04 - accuracy: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 122ms/step - loss: 1.4290e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9310 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 7.9923e-05 - accuracy: 1.0000\n",
      "Epoch 28: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 115ms/step - loss: 8.0919e-05 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9310 - lr: 2.5000e-04\n",
      "Epoch 29/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.3731e-04 - accuracy: 1.0000\n",
      "Epoch 29: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 129ms/step - loss: 1.3735e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9310 - lr: 2.5000e-04\n",
      "Epoch 30/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.9020e-04 - accuracy: 1.0000\n",
      "Epoch 30: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 141ms/step - loss: 1.8927e-04 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9310 - lr: 2.5000e-04\n",
      "Epoch 31/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 9.4073e-05 - accuracy: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 157ms/step - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.1532e-05 - accuracy: 1.0000\n",
      "Epoch 32: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "61/61 [==============================] - 8s 140ms/step - loss: 7.1532e-05 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9304 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "59/61 [============================>.] - ETA: 0s - loss: 7.8499e-05 - accuracy: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 122ms/step - loss: 7.7622e-05 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 8.0525e-05 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 120ms/step - loss: 8.0598e-05 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 6.9287e-05 - accuracy: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 145ms/step - loss: 6.8893e-05 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 7.8339e-05 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 156ms/step - loss: 7.8506e-05 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 7.2256e-05 - accuracy: 1.0000\n",
      "Epoch 37: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 126ms/step - loss: 7.1818e-05 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9302 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.3928e-04 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 145ms/step - loss: 1.3858e-04 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9301 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.2219e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 12s 206ms/step - loss: 1.2219e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9302 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.7304e-05 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 129ms/step - loss: 6.7304e-05 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9302 - lr: 1.2500e-04\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.6274e-05 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 123ms/step - loss: 6.6274e-05 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9301 - lr: 1.2500e-04\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.9137e-05 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "61/61 [==============================] - 10s 166ms/step - loss: 5.9137e-05 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9300 - lr: 1.2500e-04\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.2161e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 135ms/step - loss: 1.2161e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9299 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.8724e-05 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 154ms/step - loss: 5.8724e-05 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9299 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.0820e-05 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 147ms/step - loss: 6.0820e-05 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9298 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.1894e-05 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 133ms/step - loss: 5.1894e-05 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9298 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 9.2153e-05 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 137ms/step - loss: 9.2153e-05 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9299 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 5.6654e-05 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 5.6972e-05 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9298 - lr: 6.2500e-05\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 7.6168e-05 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 11s 178ms/step - loss: 7.6168e-05 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9299 - lr: 6.2500e-05\n",
      "Epoch 50/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 6.2379e-05 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 149ms/step - loss: 6.2241e-05 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9298 - lr: 6.2500e-05\n",
      "Epoch 51/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 1.1294e-04 - accuracy: 1.0000\n",
      "Epoch 51: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 10s 160ms/step - loss: 1.1277e-04 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9298 - lr: 6.2500e-05\n",
      "Epoch 52/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 4.7340e-05 - accuracy: 1.0000\n",
      "Epoch 52: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "61/61 [==============================] - 9s 143ms/step - loss: 4.7569e-05 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9296 - lr: 6.2500e-05\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.8899e-05 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 128ms/step - loss: 5.8899e-05 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9297 - lr: 3.1250e-05\n",
      "Epoch 54/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 4.9276e-05 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 126ms/step - loss: 4.8978e-05 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9296 - lr: 3.1250e-05\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.2338e-05 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 127ms/step - loss: 4.2338e-05 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9296 - lr: 3.1250e-05\n",
      "Epoch 56/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 6.0326e-05 - accuracy: 1.0000\n",
      "Epoch 56: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 138ms/step - loss: 6.0029e-05 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9295 - lr: 3.1250e-05\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.8578e-05 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 139ms/step - loss: 4.8578e-05 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9293 - lr: 3.1250e-05\n",
      "Epoch 58/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 6.0131e-05 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 139ms/step - loss: 5.9919e-05 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9293 - lr: 3.1250e-05\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.5673e-05 - accuracy: 1.0000\n",
      "Epoch 59: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 141ms/step - loss: 5.5673e-05 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9292 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 4.4066e-05 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 8s 126ms/step - loss: 4.4066e-05 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9292 - lr: 3.1250e-05\n",
      "Epoch 61/100\n",
      "60/61 [============================>.] - ETA: 0s - loss: 6.6164e-05 - accuracy: 1.0000\n",
      "Epoch 61: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 7s 123ms/step - loss: 6.5817e-05 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9292 - lr: 3.1250e-05\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 6.1847e-05 - accuracy: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 0.96331\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "61/61 [==============================] - 8s 127ms/step - loss: 6.1847e-05 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9293 - lr: 3.1250e-05\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6406e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 9s 150ms/step - loss: 1.6406e-04 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9293 - lr: 1.5625e-05\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.0469e-04 - accuracy: 1.0000\n",
      "Epoch 64: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 16s 271ms/step - loss: 1.0469e-04 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9293 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.2040e-05 - accuracy: 1.0000\n",
      "Epoch 65: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 26s 431ms/step - loss: 5.2040e-05 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9293 - lr: 1.5625e-05\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 5.0656e-05 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 0.96331\n",
      "61/61 [==============================] - 25s 419ms/step - loss: 5.0656e-05 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9293 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "36/61 [================>.............] - ETA: 2s - loss: 6.1314e-05 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 모델 추가 학습\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1812\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m-> 1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m \u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_increment\u001b[49m\n\u001b[0;32m   1813\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\mshof\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1431\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1428\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps_remaining\n\u001b[0;32m   1429\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_increment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 기존 모델 로드\n",
    "model = load_model('models/model_20words_90.keras')\n",
    "\n",
    "# 모델 추가 학습\n",
    "history = model.fit(\n",
    "    new_x, new_y,\n",
    "    validation_data=(x_data, y_data),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, verbose=1, mode='auto'),\n",
    "        # EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 데이터/검증 데이터 정확도/손실 그래프\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train accuracy')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val accuracy')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
